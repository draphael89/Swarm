import { describe, expect, it } from 'vitest'
import { AgentRuntime } from '../swarm/agent-runtime.js'
import type { AgentDescriptor } from '../swarm/types.js'

class FakeSession {
  isStreaming = false
  isCompacting = false
  promptCalls: string[] = []
  promptImageCounts: number[] = []
  followUpCalls: string[] = []
  steerCalls: string[] = []
  steerImageCounts: number[] = []
  userMessageCalls: Array<string | Array<{ type: string }>> = []
  compactCalls = 0
  abortCalls = 0
  disposeCalls = 0
  listener: ((event: any) => void) | undefined
  contextUsage: { tokens?: number; contextWindow?: number; percent?: number } | undefined

  async prompt(message: string, options?: { images?: Array<{ type: string }> }): Promise<void> {
    this.promptCalls.push(message)
    this.promptImageCounts.push(options?.images?.length ?? 0)
  }

  async followUp(message: string): Promise<void> {
    this.followUpCalls.push(message)
  }

  async steer(message: string, images?: Array<{ type: string }>): Promise<void> {
    this.steerCalls.push(message)
    this.steerImageCounts.push(images?.length ?? 0)
  }

  async sendUserMessage(content: string | Array<{ type: string }>): Promise<void> {
    this.userMessageCalls.push(content)
  }

  async compact(): Promise<void> {
    this.compactCalls += 1
  }

  getContextUsage(): { tokens?: number; contextWindow?: number; percent?: number } | undefined {
    return this.contextUsage
  }

  async abort(): Promise<void> {
    this.abortCalls += 1
  }

  dispose(): void {
    this.disposeCalls += 1
  }

  subscribe(listener: (event: any) => void): () => void {
    this.listener = listener
    return () => {
      this.listener = undefined
    }
  }

  emit(event: any): void {
    this.listener?.(event)
  }
}

function makeDescriptor(): AgentDescriptor {
  return {
    agentId: 'worker',
    displayName: 'Worker',
    role: 'worker',
    managerId: 'manager',
    status: 'idle',
    createdAt: '2026-01-01T00:00:00.000Z',
    updatedAt: '2026-01-01T00:00:00.000Z',
    cwd: '/tmp/project',
    model: {
      provider: 'openai-codex',
      modelId: 'gpt-5.3-codex',
      thinkingLevel: 'medium',
    },
    sessionFile: '/tmp/project/worker.jsonl',
  }
}

function createDeferred(): { promise: Promise<void>; resolve: () => void } {
  let resolve = () => {}
  const promise = new Promise<void>((nextResolve) => {
    resolve = nextResolve
  })

  return { promise, resolve }
}

async function flushAsyncWork(): Promise<void> {
  await Promise.resolve()
  await Promise.resolve()
  await new Promise((resolve) => setTimeout(resolve, 0))
}

describe('AgentRuntime', () => {
  it('queues steer for all messages when runtime is busy', async () => {
    const session = new FakeSession()

    const runtime = new AgentRuntime({
      descriptor: makeDescriptor(),
      session: session as any,
      callbacks: {
        onStatusChange: () => {},
      },
    })

    session.isStreaming = true

    const autoReceipt = await runtime.sendMessage('auto message')
    const followUpReceipt = await runtime.sendMessage('explicit followup', 'followUp')
    const steerReceipt = await runtime.sendMessage('steer message', 'steer')

    expect(autoReceipt.acceptedMode).toBe('steer')
    expect(followUpReceipt.acceptedMode).toBe('steer')
    expect(steerReceipt.acceptedMode).toBe('steer')
    expect(session.followUpCalls).toEqual([])
    expect(session.steerCalls).toEqual(['auto message', 'explicit followup', 'steer message'])
  })

  it('queues steer while prompt dispatch is in progress', async () => {
    const session = new FakeSession()
    const deferred = createDeferred()

    session.prompt = async (message: string): Promise<void> => {
      session.promptCalls.push(message)
      await deferred.promise
    }

    const runtime = new AgentRuntime({
      descriptor: makeDescriptor(),
      session: session as any,
      callbacks: {
        onStatusChange: () => {},
      },
    })

    const first = await runtime.sendMessage('first prompt')
    const second = await runtime.sendMessage('queued auto')
    const third = await runtime.sendMessage('queued followup', 'followUp')

    expect(first.acceptedMode).toBe('prompt')
    expect(second.acceptedMode).toBe('steer')
    expect(third.acceptedMode).toBe('steer')
    expect(session.promptCalls).toEqual(['first prompt'])
    expect(session.followUpCalls).toEqual([])
    expect(session.steerCalls).toEqual(['queued auto', 'queued followup'])

    deferred.resolve()
    await Promise.resolve()
  })

  it('consumes pending queue when queued user message starts', async () => {
    const session = new FakeSession()
    const statuses: number[] = []

    const runtime = new AgentRuntime({
      descriptor: makeDescriptor(),
      session: session as any,
      callbacks: {
        onStatusChange: (_agentId, _status, pendingCount) => {
          statuses.push(pendingCount)
        },
      },
    })

    session.isStreaming = true
    await runtime.sendMessage('queued one', 'auto')
    expect(runtime.getPendingCount()).toBe(1)

    session.emit({
      type: 'message_start',
      message: {
        role: 'user',
        content: 'queued one',
      },
    })

    expect(runtime.getPendingCount()).toBe(0)
    expect(statuses.at(-1)).toBe(0)
  })

  it('passes image attachments through prompt options when text is present', async () => {
    const session = new FakeSession()

    const runtime = new AgentRuntime({
      descriptor: makeDescriptor(),
      session: session as any,
      callbacks: {
        onStatusChange: () => {},
      },
    })

    await runtime.sendMessage({
      text: 'describe this image',
      images: [{ mimeType: 'image/png', data: 'aGVsbG8=' }],
    })

    expect(session.promptCalls).toEqual(['describe this image'])
    expect(session.promptImageCounts).toEqual([1])
    expect(session.userMessageCalls).toHaveLength(0)
  })

  it('uses sendUserMessage for image-only prompts', async () => {
    const session = new FakeSession()

    const runtime = new AgentRuntime({
      descriptor: makeDescriptor(),
      session: session as any,
      callbacks: {
        onStatusChange: () => {},
      },
    })

    await runtime.sendMessage({
      text: '',
      images: [{ mimeType: 'image/png', data: 'aGVsbG8=' }],
    })

    expect(session.promptCalls).toHaveLength(0)
    expect(session.userMessageCalls).toHaveLength(1)
    expect(Array.isArray(session.userMessageCalls[0])).toBe(true)
  })

  it('surfaces prompt failures, resets status to idle, and invokes onAgentEnd', async () => {
    const session = new FakeSession()
    const statuses: string[] = []
    const runtimeErrors: Array<{ phase: string; message: string }> = []
    let agentEndCalls = 0

    session.prompt = async (): Promise<void> => {
      session.emit({ type: 'agent_start' })
      throw new Error('provider outage')
    }

    const runtime = new AgentRuntime({
      descriptor: makeDescriptor(),
      session: session as any,
      callbacks: {
        onStatusChange: (_agentId, status) => {
          statuses.push(status)
        },
        onRuntimeError: (_agentId, error) => {
          runtimeErrors.push({
            phase: error.phase,
            message: error.message,
          })
        },
        onAgentEnd: () => {
          agentEndCalls += 1
        },
      },
    })

    const receipt = await runtime.sendMessage('trigger failure')
    expect(receipt.acceptedMode).toBe('prompt')

    await flushAsyncWork()

    expect(runtimeErrors).toEqual([
      expect.objectContaining({
        phase: 'prompt_dispatch',
        message: 'provider outage',
      }),
    ])
    expect(statuses).toContain('streaming')
    expect(statuses).toContain('idle')
    expect(runtime.getStatus()).toBe('idle')
    expect(agentEndCalls).toBe(1)
  })

  it('retries prompt dispatch once for transient failures before succeeding', async () => {
    const session = new FakeSession()
    const runtimeErrors: Array<{ phase: string; message: string }> = []
    let promptAttempts = 0

    session.prompt = async (message: string): Promise<void> => {
      session.promptCalls.push(message)
      promptAttempts += 1
      if (promptAttempts === 1) {
        throw new Error('temporary provider outage')
      }
    }

    const runtime = new AgentRuntime({
      descriptor: makeDescriptor(),
      session: session as any,
      callbacks: {
        onStatusChange: () => {},
        onRuntimeError: (_agentId, error) => {
          runtimeErrors.push({
            phase: error.phase,
            message: error.message,
          })
        },
      },
    })

    const receipt = await runtime.sendMessage('retry me')
    expect(receipt.acceptedMode).toBe('prompt')

    await flushAsyncWork()

    expect(session.promptCalls).toEqual(['retry me', 'retry me'])
    expect(runtimeErrors).toEqual([])
    expect(runtime.getStatus()).toBe('idle')
  })

  it('clears queued pending deliveries when prompt dispatch fails after retries', async () => {
    const session = new FakeSession()
    const deferred = createDeferred()
    const pendingStatuses: number[] = []
    const runtimeErrors: Array<{ phase: string; details?: Record<string, unknown> }> = []
    let promptAttempts = 0

    session.prompt = async (message: string): Promise<void> => {
      session.promptCalls.push(message)
      promptAttempts += 1

      if (promptAttempts === 1) {
        await deferred.promise
      }

      throw new Error('provider outage')
    }

    const runtime = new AgentRuntime({
      descriptor: makeDescriptor(),
      session: session as any,
      callbacks: {
        onStatusChange: (_agentId, _status, pendingCount) => {
          pendingStatuses.push(pendingCount)
        },
        onRuntimeError: (_agentId, error) => {
          runtimeErrors.push({
            phase: error.phase,
            details: error.details,
          })
        },
      },
    })

    const first = await runtime.sendMessage('first prompt')
    const queued = await runtime.sendMessage('queued followup')

    expect(first.acceptedMode).toBe('prompt')
    expect(queued.acceptedMode).toBe('steer')
    expect(runtime.getPendingCount()).toBe(1)
    expect(session.steerCalls).toEqual(['queued followup'])

    deferred.resolve()
    await flushAsyncWork()

    expect(runtime.getPendingCount()).toBe(0)
    expect(runtimeErrors).toEqual([
      expect.objectContaining({
        phase: 'prompt_dispatch',
        details: expect.objectContaining({
          droppedPendingCount: 1,
          attempt: 2,
          maxAttempts: 2,
        }),
      }),
    ])
    expect(pendingStatuses).toContain(1)
    expect(pendingStatuses).toContain(0)
    expect(runtime.getStatus()).toBe('idle')
  })

  it('reports compaction-related prompt failures with compaction phase', async () => {
    const session = new FakeSession()
    const phases: string[] = []

    session.prompt = async (): Promise<void> => {
      throw new Error('auto compaction failed while preparing prompt')
    }

    const runtime = new AgentRuntime({
      descriptor: makeDescriptor(),
      session: session as any,
      callbacks: {
        onStatusChange: () => {},
        onRuntimeError: (_agentId, error) => {
          phases.push(error.phase)
        },
      },
    })

    await runtime.sendMessage('trigger compaction failure')
    await flushAsyncWork()

    expect(phases.at(-1)).toBe('compaction')
    expect(runtime.getStatus()).toBe('idle')
  })

  it('runs proactive compaction before prompt dispatch when context usage exceeds threshold', async () => {
    const session = new FakeSession()
    session.contextUsage = {
      tokens: 171_000,
      contextWindow: 200_000,
      percent: 0.855,
    }

    const runtime = new AgentRuntime({
      descriptor: makeDescriptor(),
      session: session as any,
      callbacks: {
        onStatusChange: () => {},
      },
    })

    const receipt = await runtime.sendMessage('needs compaction')
    expect(receipt.acceptedMode).toBe('prompt')

    await flushAsyncWork()

    expect(session.compactCalls).toBe(1)
    expect(session.promptCalls).toEqual(['needs compaction'])
  })

  it('surfaces assistant message_end errors when provider reports a context overflow', async () => {
    const session = new FakeSession()
    const runtimeErrors: Array<{ phase: string; message: string; details?: Record<string, unknown> }> = []

    new AgentRuntime({
      descriptor: makeDescriptor(),
      session: session as any,
      callbacks: {
        onStatusChange: () => {},
        onRuntimeError: (_agentId, error) => {
          runtimeErrors.push({
            phase: error.phase,
            message: error.message,
            details: error.details,
          })
        },
      },
    })

    session.emit({
      type: 'message_end',
      message: {
        role: 'assistant',
        content: [{ type: 'text', text: '' }],
        stopReason: 'error',
        errorMessage: 'prompt is too long: 180201 tokens > 180000 maximum',
        provider: 'anthropic',
        model: 'claude-sonnet',
      },
    })

    await flushAsyncWork()

    expect(runtimeErrors).toEqual([
      expect.objectContaining({
        phase: 'compaction',
        message: 'prompt is too long: 180201 tokens > 180000 maximum',
        details: expect.objectContaining({
          source: 'assistant_message_end',
          contextOverflow: true,
        }),
      }),
    ])
  })

  it('resets stalled streaming sessions via watchdog timeout and surfaces an error', async () => {
    const session = new FakeSession()
    const statuses: string[] = []
    const runtimeErrors: Array<{ phase: string; details?: Record<string, unknown> }> = []
    let agentEndCalls = 0

    const runtime = new AgentRuntime({
      descriptor: makeDescriptor(),
      session: session as any,
      callbacks: {
        onStatusChange: (_agentId, status) => {
          statuses.push(status)
        },
        onRuntimeError: (_agentId, error) => {
          runtimeErrors.push({
            phase: error.phase,
            details: error.details,
          })
        },
        onAgentEnd: () => {
          agentEndCalls += 1
        },
      },
    })

    session.emit({ type: 'agent_start' })
    await flushAsyncWork()

    ;(runtime as any).streamingInactivityTimeoutMs = 1
    ;(runtime as any).lastEventAtMs = Date.now() - 5

    await (runtime as any).runHealthCheck()
    await flushAsyncWork()

    expect(runtime.getStatus()).toBe('idle')
    expect(statuses).toContain('streaming')
    expect(statuses).toContain('idle')
    expect(runtimeErrors).toEqual([
      expect.objectContaining({
        phase: 'watchdog_timeout',
        details: expect.objectContaining({
          reason: 'streaming',
        }),
      }),
    ])
    expect(session.abortCalls).toBe(1)
    expect(agentEndCalls).toBe(1)
  })

  it('terminates by aborting active session and marking status terminated', async () => {
    const session = new FakeSession()

    const runtime = new AgentRuntime({
      descriptor: makeDescriptor(),
      session: session as any,
      callbacks: {
        onStatusChange: () => {},
      },
    })

    await runtime.terminate({ abort: true })

    expect(session.abortCalls).toBe(1)
    expect(session.disposeCalls).toBe(1)
    expect(runtime.getStatus()).toBe('terminated')
  })
})
